{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **A Simple Image Classifier with MobileNet.**\n",
        "\n",
        "*   To see the performance of the model please run all the cells and check the output of the last cell\n",
        "\n"
      ],
      "metadata": {
        "id": "F7ho5X7durlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cloning the repository here and getting the required data for training\n",
        "# and testing\n",
        "!git clone https://github.com/theUnrealSamurai/simple_classifier.git"
      ],
      "metadata": {
        "id": "RM447DBCnqsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565cb69c-7182-4cd2-c51c-82073b1e0c16"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'simple_classifier'...\n",
            "remote: Enumerating objects: 214, done.\u001b[K\n",
            "remote: Counting objects: 100% (214/214), done.\u001b[K\n",
            "remote: Compressing objects: 100% (213/213), done.\u001b[K\n",
            "remote: Total 214 (delta 0), reused 214 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (214/214), 4.83 MiB | 22.00 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries here and setting the random seed to generate\n",
        "# the same output results everytime. If the random seed is not set,\n",
        "# the performance of the model may vary everytime you train it.\n",
        "\n",
        "\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    pd.np.random.seed(seed)\n",
        "    sklearn.utils.check_random_state(seed)\n",
        "\n",
        "set_random_seed(13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB9PKOszsjqW",
        "outputId": "755fd252-af3e-413b-bc3d-d81efc7c353f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-37b209f44fc4>:16: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
            "  pd.np.random.seed(seed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RkaxEWD76MFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2800c9ac-9e70-46bc-ebf5-595faf2a0ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 174 images belonging to 7 classes.\n",
            "Found 16 images belonging to 7 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n",
            "Epoch 1/9\n",
            "6/6 [==============================] - 60s 7s/step - loss: 0.5138 - accuracy: 0.8161 - val_loss: 0.7513 - val_accuracy: 0.8750\n",
            "Epoch 2/9\n",
            "6/6 [==============================] - 44s 8s/step - loss: 0.0137 - accuracy: 0.9943 - val_loss: 1.1554 - val_accuracy: 0.8750\n",
            "Epoch 3/9\n",
            "6/6 [==============================] - 43s 7s/step - loss: 0.0137 - accuracy: 0.9943 - val_loss: 0.8561 - val_accuracy: 0.8750\n",
            "Epoch 4/9\n",
            "6/6 [==============================] - 42s 7s/step - loss: 0.0064 - accuracy: 0.9943 - val_loss: 0.3066 - val_accuracy: 0.9375\n",
            "Epoch 5/9\n",
            "6/6 [==============================] - 44s 8s/step - loss: 6.6014e-04 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.9375\n",
            "Epoch 6/9\n",
            "6/6 [==============================] - 43s 7s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9375\n",
            "Epoch 7/9\n",
            "6/6 [==============================] - 47s 8s/step - loss: 4.9289e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 8/9\n",
            "6/6 [==============================] - 42s 7s/step - loss: 4.8860e-04 - accuracy: 1.0000 - val_loss: 2.9854e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/9\n",
            "6/6 [==============================] - 43s 7s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4077e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# path to the folder where the training images are saved.\n",
        "data_folder = '/content/simple_classifier/data/train_data'\n",
        "\n",
        "# Defining Image size and batch size here.\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.1 # Change the size of the validation dataset here.\n",
        "                         # Since the size of the dataset is small I'm using 0.1\n",
        ")\n",
        "\n",
        "# Generating the Training dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_folder,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Generating the Validation dataset\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_folder,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Getting the pretrained mobile net model to finetune it for our dataset.\n",
        "base_model = MobileNet(include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Modifying the output nodes to fit for only 7 classes that we have.\n",
        "# i.e [bar, cherry, elephant, clown, z, grape, bell]\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Training and saving the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 9\n",
        "model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
        "\n",
        "model.save('trained_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model to TFLite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model to a file\n",
        "with open('classifier.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYKT114tn2k_",
        "outputId": "807f84a9-79e9-435f-9a10-c7f63b09b7d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 28). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/classifier.tflite /content/drive/MyDrive/junk\n",
        "!cp /content/trained_model.h5 /content/drive/MyDrive/junk"
      ],
      "metadata": {
        "id": "geWYAFWfYFOh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "yZ1BFll9YFL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvkyv4TmYFJk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}